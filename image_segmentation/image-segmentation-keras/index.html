<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="canonical" href="https://www.data-mining.co.nz/applied-deep-learning/image_segmentation/image-segmentation-keras/">
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Image Segmenation Keras - Applied Deep Learning</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../css/theme.css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Image Segmenation Keras";
    var mkdocs_page_input_path = "image_segmentation/image-segmentation-keras.md";
    var mkdocs_page_url = "/applied-deep-learning/image_segmentation/image-segmentation-keras/";
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Applied Deep Learning</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../prerequisites/">Prerequisites</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Image classification</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../image_classification/">Introduction</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../image_classification/annotate/">Annotate</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../image_classification/frameworks/">Frameworks</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Object detection</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../object_detection/">Introduction</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../object_detection/annotate/">Annotate</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../object_detection/frameworks/">Frameworks</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Instance segmentation</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../instance_segmentation/">Introduction</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../instance_segmentation/annotate/">Annotate</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../instance_segmentation/frameworks/">Frameworks</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Image segmentation</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../">Introduction</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../annotate/">Annotate</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../frameworks/">Frameworks</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Applied Deep Learning</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
    
    <li>Image Segmenation Keras</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/waikato-datamining/applied-deep-learning/edit/main/docs/image_segmentation/image-segmentation-keras.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <p><a href="https://github.com/divamgupta/image-segmentation-keras">Image Segmenation Keras</a> is a Keras/Tensorflow
based image segmentation framework. Custom docker images with additional tools are available from here:</p>
<p><a href="https://github.com/waikato-datamining/tensorflow/tree/master/image-segmentation-keras">https://github.com/waikato-datamining/tensorflow/tree/master/image-segmentation-keras</a></p>
<h2 id="prerequisites">Prerequisites<a class="headerlink" href="#prerequisites" title="Permanent link">#</a></h2>
<p>Make sure you have the directory structure created as outlined in the <a href="../../prerequisites/">Prerequisites</a>.</p>
<h2 id="data">Data<a class="headerlink" href="#data" title="Permanent link">#</a></h2>
<p>In this example, we will use the <a href="https://datasets.cms.waikato.ac.nz/ufdl/camvid12/">CamVid-12</a>
dataset, which consists of still images from dashcam videos from a city environment (12 different labels).</p>
<p>Download the dataset from the following URL into the <em>data</em> directory and extract it:</p>
<p><a href="https://datasets.cms.waikato.ac.nz/ufdl/data/camvid12/camvid12-grayscale.zip">https://datasets.cms.waikato.ac.nz/ufdl/data/camvid12/camvid12-grayscale.zip</a></p>
<p>Once extracted, rename the <em>grayscale</em> directory to <em>camvid-grayscale</em>.</p>
<p>Now we have to convert the format from <em>grayscale</em> into <em>blue channel</em>, which the framework uses.
We can do this by using the <a href="https://github.com/waikato-ufdl/wai-annotations">wai.annotations</a> library. 
At the same time, we can split the dataset into <em>train</em>, <em>validation</em> and <em>test</em> subsets.</p>
<p>From within the <code>applied_deep_learning</code> directory, run the following command:</p>
<pre><code class="language-bash">docker run -u $(id -u):$(id -g) \
  -v `pwd`:/workspace \
  -t waikatoufdl/wai.annotations:latest \
  wai-annotations convert \
    from-grayscale-is \
      -i &quot;/workspace/data/camvid-grayscale/*.png&quot; \
      --labels sky building pole road pavement tree signsymbol fence car pedestrian bicyclist unlabelled \
    to-blue-channel-is \
      -o /workspace/data/camvid-bluechannel-split \
      --split-names train val test \
      --split-ratios 70 15 15
</code></pre>
<h2 id="training">Training<a class="headerlink" href="#training" title="Permanent link">#</a></h2>
<p>For training, we will use the following docker image:</p>
<pre><code>waikatodatamining/image-segmentation-keras:1.14.0_0.3.0
</code></pre>
<p>The training script is called <code>keras_seg_train</code>, for which we can invoke the help screen as follows:</p>
<pre><code class="language-bash">docker run -t waikatodatamining/image-segmentation-keras:1.14.0_0.3.0 keras_seg_train --help 
</code></pre>
<p>It is good practice creating a separate sub-directory for each training run, with a directory name that hints at
what dataset and model were used. So for our first training run, which will use mainly default parameters, we will 
create the following directory in the <code>output</code> folder:</p>
<pre><code>camvid12-keras-unet50
</code></pre>
<p>Image Segmentation Keras does not use a config file, but can be configured via command-line parameters
instead:</p>
<ul>
<li>the number of classes (<code>--n_classes</code>) is actual classes plus background </li>
<li>the width/height of the inputs must be multiples of 32 (<code>--input_height</code>, <code>--input_width</code>) </li>
<li>the output directory is specified via <code>--checkpoints_path</code> (make sure to have a trailing slash!) </li>
<li>in our case, the images and the annotations reside in the same directories, so <code>--train_images</code> and <code>--train_annotations</code> 
  point to the same directory (analog for <code>--val_images</code> and <code>--val_annotations</code>)</li>
<li>with <code>--epochs</code> you can specify for how long the model will get trained</li>
<li><code>--model_name</code> specifies the architecture and backend (see <a href="https://github.com/divamgupta/image-segmentation-keras#models">here</a> for available options)</li>
</ul>
<p>Kick off the training of a U-Net with a ResNet50 backend using the following command:</p>
<pre><code class="language-bash">docker run \
  -u $(id -u):$(id -g) \
  --gpus=all \
  -v `pwd`:/workspace \
  -v `pwd`/cache:/tmp/.keras \
  -t waikatodatamining/image-segmentation-keras:1.14.0_0.3.0 \
  keras_seg_train \
  --checkpoints_path /workspace/output/camvid12-keras-unet50/ \
  --train_images /workspace/data/camvid-bluechannel-split/train \
  --train_annotations /workspace/data/camvid-bluechannel-split/train \
  --val_images /workspace/data/camvid-bluechannel-split/val \
  --val_annotations /workspace/data/camvid-bluechannel-split/val \
  --epochs 10 \
  --n_classes 13 \
  --input_height 384 \
  --input_width 480 \
  --model_name resnet50_unet
</code></pre>
<h2 id="predicting">Predicting<a class="headerlink" href="#predicting" title="Permanent link">#</a></h2>
<p>Using the <code>keras_seg_poll</code> script, we can batch-process images placed in the <code>predictions/in</code> directory
as follows (e.g., from our <em>test</em> subset): </p>
<pre><code class="language-bash">docker run \
  -u $(id -u):$(id -g) \
  --gpus=all \
  -v `pwd`:/workspace \
  -v `pwd`/cache:/tmp/.keras \
  -t waikatodatamining/image-segmentation-keras:1.14.0_0.3.0 \
  keras_seg_poll \
  --checkpoints_path /workspace/output/camvid12-keras-unet50/ \
  --prediction_in /workspace/predictions/in \
  --prediction_out /workspace/predictions/out
</code></pre>
<p><strong>Example prediction</strong></p>
<p><img alt="Screenshot" src="../img/isk-0016E5_05310.png" /> </p>
<p><img alt="Screenshot" src="../img/isk-0016E5_05310-overlay.png" /></p>
              
            </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/waikato-datamining/applied-deep-learning/" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
