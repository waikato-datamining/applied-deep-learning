{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"While working on a number of projects over the years, we have developed (and maintain) a number of Python libraries and Docker images that can be used for various deep learning tasks. Especially the use of Docker made it a lot easier and faster to apply algorithms to new datasets. If you have not used Docker before, we recommend you to have a look at our introduction called Docker for Data Scientists . The following domains are covered: Image classification Object detection Instance segmentation Image segmentation","title":"Home"},{"location":"image_classification/","text":"Image classification is the simplest and least computational expensive task, as it classifies whole images, assigning them a category. Before you delve into training models, take a look at how you need to annotate your data . The following frameworks are available: wai.pytorchimageclass wai.tfimageclass wai.tflite_model_maker","title":"Introduction"},{"location":"image_classification/annotate/","text":"Annotating data for image classification is straight forward. Since we are classifying whole images, we can simply use the directory layout for annotating images. In the example below, we have a dataset called flowers . The sub-directories below the flowers directory represent the labels for the images containing within the sub-directories. | +- flowers | +- daisy | +- dandelion | +- roses | +- sunflowers | +- tulip NB: To avoid any issues, the labels should be lowercase and underscores should be used instead of blanks/spaces.","title":"Annotate"},{"location":"image_classification/wai.pytorchimageclass/","text":"With wai.pytorchimageclass it is possible to train various image classification network architectues and also perform inference. The code is based on this Pytorch example: https://github.com/pytorch/examples/tree/master/imagenet Specifically, this commit: 49e1a8847c8c4d8d3c576479cb2fe2fd2ac583de","title":"wai.pytorchimageclass"},{"location":"image_classification/wai.tfimageclass/","text":"","title":"wai.tfimageclass"},{"location":"image_classification/wai.tflite_model_maker/","text":"","title":"wai.tflite_model_maker"},{"location":"image_segmentation/","text":"Image segmentation classifies individual pixels within an image, assigning them a label (i.e., a color). Input Annotation/Output Before you delve into training models, take a look at how you need to annotate your data . The following frameworks are available: Image Segmentation Keras","title":"Introduction"},{"location":"image_segmentation/annotate/","text":"You can use the ADAMS framework for annotating your images. ADAMS comes pre-bundled in various setups and we need the adams-annotator bundle. You can get either: snapshot release (21.12.0 or later) In the Flow editor (available from the Tools menu in ADAMS), you can load and execute the follow workflow (which is part of your ADAMS installation when downloading it as zip file): adams-imaging-image_segmentation_annotation.flow","title":"Annotate"},{"location":"image_segmentation/image-segmentation-keras/","text":"","title":"Image Segmentation Keras"},{"location":"instance_segmentation/","text":"Instance segmentation not only finds objects within images, it also learns the shape of the objects rather than just a simple rectangle/bounding box. However, this makes the algorithms computationally more expensive and more memory hungry. Before you delve into training models, take a look at how you need to annotate your data . The following frameworks are available: Detectron2","title":"Introduction"},{"location":"instance_segmentation/annotate/","text":"You can use the ADAMS framework for annotating your images. ADAMS comes pre-bundled in various setups and we need the adams-annotator bundle. You can get either: snapshot release (21.12.0 or later) In the Flow editor (available from the Tools menu in ADAMS), you can load and execute the follow workflow (which is part of your ADAMS installation when downloading it as zip file): adams-imaging-annotate_objects.flow When prompted, use object_shape as Selection type .","title":"Annotate"},{"location":"instance_segmentation/detectron2/","text":"","title":"Detectron2"},{"location":"object_detection/","text":"Object detection detects one or more objects within an image and assigns each one of them a label, as opposed to image classification which assigns a lable to the whole image. The predicted locations are typically rectangles (aka bounding boxes). If you are looking for shapes or polygons, then have a look at instance segmentation . Before you delve into training models, take a look at how you need to annotate your data . The following frameworks are available: MMDetection wai.tflite_model_maker","title":"Introduction"},{"location":"object_detection/annotate/","text":"You can use the ADAMS framework for annotating your images. ADAMS comes pre-bundled in various setups and we need the adams-annotator bundle. You can get either: snapshot release (21.12.0 or later) In the Flow editor (available from the Tools menu in ADAMS), you can load and execute the follow workflow (which is part of your ADAMS installation when downloading it as zip file): adams-imaging-annotate_objects.flow When prompted, use bounding_box as Selection type .","title":"Annotate"},{"location":"object_detection/mmdetection/","text":"","title":"MMDetection"},{"location":"object_detection/wai.tflite_model_maker/","text":"","title":"wai.tflite_model_maker"}]}